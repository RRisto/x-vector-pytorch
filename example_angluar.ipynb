{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79703d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from x_vectors.models.LDE import LDE\n",
    "from x_vectors.models.angleloss import AngleLinear\n",
    "from x_vectors.models.tdnn import TDNN\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import utils\n",
    "from utils.utils import speech_collate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9473cb7e",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3887130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(audio_filepath, sr=16000, min_dur_sec=4):\n",
    "    audio_data, fs = librosa.load(audio_filepath, sr=sr)\n",
    "    len_file = len(audio_data)\n",
    "\n",
    "    if len_file < int(min_dur_sec * sr):\n",
    "        dummy = np.zeros((1, int(min_dur_sec * sr) - len_file))\n",
    "        extened_wav = np.concatenate((audio_data, dummy[0]))\n",
    "    else:\n",
    "\n",
    "        extened_wav = audio_data\n",
    "    return extened_wav\n",
    "\n",
    "def lin_spectogram_from_wav(wav, hop_length, win_length, n_fft=512):\n",
    "    linear = librosa.stft(wav, n_fft=n_fft, win_length=win_length, hop_length=hop_length)  # linear spectrogram\n",
    "    return linear.T\n",
    "\n",
    "def load_data(filepath, sr=16000, min_dur_sec=4, win_length=400, hop_length=160, n_mels=40, spec_len=400, mode='train'):\n",
    "    audio_data = load_wav(filepath, sr=sr, min_dur_sec=min_dur_sec)\n",
    "    # linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_mels)\n",
    "    linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_fft=512)\n",
    "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
    "    # todo just my test, why doe they take magnitude\n",
    "    #mag = linear_spect.real\n",
    "    mag_T = mag.T\n",
    "\n",
    "    if mode == 'train':\n",
    "        randtime = np.random.randint(0, mag_T.shape[1] - spec_len)\n",
    "        spec_mag = mag_T[:, randtime:randtime + spec_len]\n",
    "    else:\n",
    "        spec_mag = mag_T\n",
    "\n",
    "    # preprocessing, subtract mean, divided by time-wise var\n",
    "    mu = np.mean(spec_mag, 0, keepdims=True)\n",
    "    std = np.std(spec_mag, 0, keepdims=True)\n",
    "    return (spec_mag - mu) / (std + 1e-5)\n",
    "\n",
    "\n",
    "class SpeechDataGenerator():\n",
    "    \"\"\"Speech dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, audio_links, labels, mode='train', sr=16000):\n",
    "        \"\"\"\n",
    "        Read the textfile and get the paths\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.sr = sr\n",
    "        self.audio_links = audio_links\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_links)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_link = self.audio_links[idx]\n",
    "        class_id = self.labels[idx]\n",
    "        spec = utils.load_data(audio_link, sr=self.sr, mode=self.mode)\n",
    "        sample = {'features': torch.from_numpy(np.ascontiguousarray(spec)),\n",
    "                  'labels': torch.from_numpy(np.ascontiguousarray(class_id))}\n",
    "        return sample\n",
    "\n",
    "\n",
    "class X_vector(nn.Module):\n",
    "    def __init__(self, input_dim=257, num_classes=8, pooling='stat', use_angular=True, device='cpu'):\n",
    "        super(X_vector, self).__init__()\n",
    "\n",
    "        self.tdnn1 = TDNN(input_dim=input_dim, output_dim=512, context_size=5, dilation=1, dropout_p=0.5)\n",
    "        self.tdnn2 = TDNN(input_dim=512, output_dim=512, context_size=3, dilation=1, dropout_p=0.5)\n",
    "        self.tdnn3 = TDNN(input_dim=512, output_dim=512, context_size=2, dilation=2, dropout_p=0.5)\n",
    "        self.tdnn4 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=1, dropout_p=0.5)\n",
    "        self.tdnn5 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=3, dropout_p=0.5)\n",
    "        self.pooling = pooling\n",
    "        #### Frame levelPooling\n",
    "        self.segment6 = nn.Linear(1024, 512)\n",
    "        self.segment7 = nn.Linear(512, 512)\n",
    "        self.output = nn.Linear(512, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.use_angluar = use_angular\n",
    "        if self.use_angluar:\n",
    "            self.fc2 = AngleLinear(num_classes, num_classes, device=device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        tdnn1_out = self.tdnn1(inputs)\n",
    "        tdnn2_out = self.tdnn2(tdnn1_out)\n",
    "        tdnn3_out = self.tdnn3(tdnn2_out)\n",
    "        tdnn4_out = self.tdnn4(tdnn3_out)\n",
    "        tdnn5_out = self.tdnn5(tdnn4_out)\n",
    "        ### Stat Pool\n",
    "        mean = torch.mean(tdnn5_out, 1)\n",
    "        std = torch.var(tdnn5_out, 1)\n",
    "        stat_pooling = torch.cat((mean, std), 1)\n",
    "        segment6_out = self.segment6(stat_pooling)\n",
    "        x_vec = self.segment7(segment6_out)\n",
    "        predictions_raw = self.output(x_vec)\n",
    "        if self.use_angluar:\n",
    "            predictions = self.fc2(predictions_raw)\n",
    "            return predictions_raw, predictions, x_vec\n",
    "        return predictions, x_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1804642d",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a50ea398",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features=load_data('data_emotion/01_01_01_01_dogs-sitting_fear.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81aa12d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 400)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d832e0a",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b6b9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen=SpeechDataGenerator(['data_emotion/01_01_01_01_dogs-sitting_fear.wav',\n",
    "                             'data_emotion/01_01_01_01_dogs-sitting_fear.wav'], \n",
    "                             [0, 0])\n",
    "\n",
    "dataloader = DataLoader(data_gen, batch_size=2, shuffle=True,\n",
    "                                collate_fn=speech_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4b66ae",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c86b0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=X_vector()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0,\n",
    "                                    betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28cc6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1029e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    " for i_batch, sample_batched in enumerate(dataloader):\n",
    "        features = torch.from_numpy(\n",
    "            np.asarray([torch_tensor.numpy().T for torch_tensor in sample_batched[0]])).float()\n",
    "        labels = torch.from_numpy(np.asarray([torch_tensor[0].numpy() for torch_tensor in sample_batched[1]]))\n",
    "        features.requires_grad = True\n",
    "        optimizer.zero_grad()\n",
    "        pred_logits_raw, pred_logits, x_vec = model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffc37fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0302, -0.0151,  0.0400, -0.0293,  0.0261,  0.0170,  0.0447, -0.0045],\n",
       "        [-0.0303, -0.0148,  0.0399, -0.0291,  0.0266,  0.0172,  0.0448, -0.0042]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_logits_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc652d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0186, -0.0076,  0.0062,  0.0255, -0.0269, -0.0188,  0.0059,  0.0215],\n",
       "         [-0.0181, -0.0076,  0.0061,  0.0255, -0.0274, -0.0194,  0.0062,  0.0217]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " tensor([[-0.2758, -0.2492, -0.2398, -0.1858, -0.3070, -0.2766, -0.2401, -0.2011],\n",
       "         [-0.2745, -0.2494, -0.2402, -0.1859, -0.3093, -0.2786, -0.2400, -0.2007]],\n",
       "        grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c516762e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0382, -0.0146, -0.0213,  ..., -0.0019, -0.0155,  0.0205],\n",
       "        [-0.0378, -0.0135, -0.0225,  ..., -0.0026, -0.0147,  0.0219]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690b044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
